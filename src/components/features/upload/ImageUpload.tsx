"use client";

import { Sparkles } from "lucide-react";
import Image from "next/image";
import { useCallback, useEffect } from "react";
import BasicContainer from "../../ui/BasicContainer";

interface ImageUploadProps {
  fileUrl: string;
  onReset: () => void;
}

export default function ImageUpload({
  fileUrl,
  onReset
}: ImageUploadProps) {
  // í…ìŠ¤íŠ¸ ìƒìˆ˜
  const TEXTS = {
    analyze: "ì˜¤ëŠ˜ì˜ ê¸°ë¶„",
    changePhoto: "ë‹¤ë¥¸ ì‚¬ì§„ìœ¼ë¡œ ë³€ê²½",
    errorFileSize: "íŒŒì¼ í¬ê¸°ëŠ” 10MB ì´í•˜ë¡œ ì„ íƒí•´ì£¼ì„¸ìš”.",
  };

  // face-api.js ëª¨ë¸ ë¡œë”©
  useEffect(() => {
    const loadModels = async () => {
      try {
        // ë™ì  importë¡œ í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œì—ì„œë§Œ ë¡œë“œ
        const faceapi = await import('face-api.js');

        // TensorFlow.js ë°±ì—”ë“œ ì„¤ì •
        await faceapi.tf.setBackend('webgl');
        await faceapi.tf.ready();

        console.log('TinyYolov2 ëª¨ë¸ ë¡œë”© ì‹œì‘...');

        // TinyYolov2 ëª¨ë¸ì„ ë¨¼ì € ë¡œë“œ (ì–¼êµ´ ê°ì§€ìš©)
        await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
        console.log('TinyYolov2 ëª¨ë¸ ë¡œë”© ì™„ë£Œ');

        // ë‚˜ë¨¸ì§€ ëª¨ë¸ë“¤ ìˆœì°¨ì ìœ¼ë¡œ ë¡œë”©
        console.log('Face Landmark ëª¨ë¸ ë¡œë”© ì¤‘...');
        await faceapi.nets.faceLandmark68Net.loadFromUri('/models');

        console.log('Face Expression ëª¨ë¸ ë¡œë”© ì¤‘...');
        await faceapi.nets.faceExpressionNet.loadFromUri('/models');

        console.log('Age Gender ëª¨ë¸ ë¡œë”© ì¤‘...');
        await faceapi.nets.ageGenderNet.loadFromUri('/models');

        console.log('ëª¨ë“  ëª¨ë¸ ë¡œë”© ì™„ë£Œ');
      } catch (error) {
        console.error('ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨:', error);
        // ê°œë°œ í™˜ê²½ì—ì„œëŠ” ë”ë¯¸ ë°ì´í„° ì‚¬ìš©
        console.log('ë”ë¯¸ ë°ì´í„° ëª¨ë“œë¡œ ì „í™˜');
      }
    };

    loadModels();
  }, []);

  const handleAnalyze = useCallback(async () => {
    try {
      // face-api.js ë¶„ì„ ì‹œì‘
      const faceapi = await import('face-api.js');

      console.log('TinyYolov2 ëª¨ë¸ì„ ì‚¬ìš©í•œ ì–¼êµ´ ê°ì§€ ì‹œì‘...');

      // ì´ë¯¸ì§€ URLì„ fetchí•˜ì—¬ blobìœ¼ë¡œ ë³€í™˜
      const response = await fetch(fileUrl);
      const blob = await response.blob();
      const img = await faceapi.bufferToImage(blob);

      // ì–¼êµ´ ê°ì§€ ë° ë¶„ì„
      const detections = await faceapi
        .detectAllFaces(img, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceExpressions()
        .withAgeAndGender();

      console.log(`ì–¼êµ´ ê°ì§€ ì™„ë£Œ: ${detections.length}ê°œ ì–¼êµ´ ë°œê²¬`);

      if (detections.length === 0) {
        throw new Error('ì–¼êµ´ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
      }

      const detection = detections[0];
      const emotions = detection.expressions;
      const age = Math.round(detection.age);
      const gender = detection.gender;

      console.log('ê°ì • ë¶„ì„ ê²°ê³¼:', emotions);
      console.log('ì¶”ê°€ ì •ë³´:', { age, gender });

      // ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ í‘œì‹œ
      const dominantEmotion = Object.entries(emotions).reduce((a, b) =>
        emotions[a[0] as keyof typeof emotions] > emotions[b[0] as keyof typeof emotions] ? a : b
      )[0] as keyof typeof emotions;

      const emotionLabels = {
        happy: "í–‰ë³µ",
        sad: "ìŠ¬í””",
        angry: "í™”ë‚¨",
        fearful: "ë‘ë ¤ì›€",
        surprised: "ë†€ëŒ",
        disgusted: "í˜ì˜¤",
        neutral: "ì¤‘ë¦½"
      };

      const dominantScore = emotions[dominantEmotion] as number;
      const dominantLabel = emotionLabels[dominantEmotion as keyof typeof emotionLabels] || dominantEmotion;

      // AI ë¬¸êµ¬ ìƒì„± (ë”ë¯¸ ë°ì´í„°)
      const aiPhrases = [
        "ì˜¤ëŠ˜ì€ ì •ë§ ì¢‹ì€ í•˜ë£¨ë„¤ìš”! âœ¨",
        "ì•½ê°„ í”¼ê³¤í•´ ë³´ì´ì‹œëŠ”ë°, í‘¹ ì‰¬ì„¸ìš”! ğŸ˜´",
        "ë°ì€ ë¯¸ì†Œê°€ ì •ë§ ì˜ˆì˜ë„¤ìš”! ğŸ˜Š",
        "ì˜¤ëŠ˜ í•˜ë£¨ë„ í™”ì´íŒ…! ğŸ’ª",
        "í‰ì˜¨í•œ í‘œì •ì´ ì¢‹ì•„ìš”! ğŸ§˜â€â™€ï¸",
        "ì—ë„ˆì§€ê°€ ë„˜ì¹˜ëŠ” í•˜ë£¨ë„¤ìš”! âš¡",
        "ì°¨ë¶„í•˜ê³  ì•ˆì •ì ì¸ ê¸°ë¶„ì´ ëŠê»´ì ¸ìš”! ğŸŒ¸",
        "ì˜¤ëŠ˜ë„ ìˆ˜ê³ í•˜ì…¨ì–´ìš”! ğŸ‘"
      ];

      const aiPhrase = aiPhrases[Math.floor(Math.random() * aiPhrases.length)];

      console.log('ë¶„ì„ ì™„ë£Œ:', { dominantEmotion, dominantLabel, dominantScore, aiPhrase });

    } catch (error) {
      console.error('ë¶„ì„ ì˜¤ë¥˜:', error);
      alert(`ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`);
    }
  }, [fileUrl]);

  return (
    <BasicContainer>
      <div className="space-y-4">
        <div className="relative w-full max-w-md mx-auto">
          {/* ì´ë¯¸ì§€ ì»¨í…Œì´ë„ˆ - ì •ì‚¬ê°í˜• ë¹„ìœ¨ë¡œ ê³ ì • */}
          <div className="relative w-full aspect-square bg-gray-50 dark:bg-gray-800 rounded-lg overflow-hidden shadow-sm">
            <Image
              src={fileUrl}
              alt="ì—…ë¡œë“œëœ ì´ë¯¸ì§€"
              fill
              className="object-cover"
              style={{ objectPosition: 'center' }}
              sizes="(max-width: 768px) 100vw, 400px"
            />
          </div>
        </div>

        <div className="space-y-2">
          {/* ë¶„ì„ ë²„íŠ¼ */}
          <button
            onClick={handleAnalyze}
            className="w-full px-6 py-3 rounded-lg font-bold transition-all text-white cursor-pointer relative overflow-hidden bg-gradient-to-r from-[hsl(245,70%,59%)] to-[hsl(245,70%,70%)] hover:shadow-lg hover:shadow-primary/25 shimmer-effect"
          >
            <div className="flex items-center justify-center gap-2">
              <Sparkles className="w-4 h-4" />
              {TEXTS.analyze}
            </div>
          </button>

          {/* ë‹¤ë¥¸ ì‚¬ì§„ìœ¼ë¡œ ë³€ê²½ ë²„íŠ¼ */}
          <button
            onClick={onReset}
            className="w-full px-4 py-2 text-sm text-muted-foreground hover:text-foreground transition-colors border-[0.5px] border-border rounded-lg hover:bg-muted cursor-pointer"
          >
            {TEXTS.changePhoto}
          </button>
        </div>

      </div>
    </BasicContainer>
  );
}
