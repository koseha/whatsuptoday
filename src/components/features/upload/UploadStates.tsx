"use client";

import { useCallback, useState, useEffect } from "react";
import { UploadBefore, ImageUpload, SupportedFormats } from "./";

type UploadState = 'before' | 'image';

export default function UploadStates() {
  const [uploadState, setUploadState] = useState<UploadState>('before');
  const [uploadedFile, setUploadedFile] = useState<File | null>(null);
  const [fileUrl, setFileUrl] = useState<string>('');
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [isModelLoaded, setIsModelLoaded] = useState(false);
  const [analysisResult, setAnalysisResult] = useState<{
    emotions: {
      happy: number;
      sad: number;
      angry: number;
      fearful: number;
      surprised: number;
      disgusted: number;
      neutral: number;
    };
    age: number;
    gender: string;
    dominantEmotion: string;
    dominantLabel: string;
    dominantScore: number;
    emotionLabels: Record<string, string>;
    aiPhrase: string;
  } | null>(null);

  // í…ìŠ¤íŠ¸ ìƒìˆ˜
  const TEXTS = {
    errorFileSize: "íŒŒì¼ í¬ê¸°ëŠ” 10MB ì´í•˜ë¡œ ì„ íƒí•´ì£¼ì„¸ìš”.",
    successAnalysis: "ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!",
    errorAnalysis: "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
  };

  // face-api.js ëª¨ë¸ ë¡œë”©
  useEffect(() => {
    const loadModels = async () => {
      try {
        // ë™ì  importë¡œ í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œì—ì„œë§Œ ë¡œë“œ
        const faceapi = await import('face-api.js');

        // TensorFlow.js ë°±ì—”ë“œ ì„¤ì •
        await faceapi.tf.setBackend('webgl');
        await faceapi.tf.ready();

        console.log('TinyYolov2 ëª¨ë¸ ë¡œë”© ì‹œì‘...');

        // TinyYolov2 ëª¨ë¸ì„ ë¨¼ì € ë¡œë“œ (ì–¼êµ´ ê°ì§€ìš©)
        await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
        console.log('TinyYolov2 ëª¨ë¸ ë¡œë”© ì™„ë£Œ');

        // ë‚˜ë¨¸ì§€ ëª¨ë¸ë“¤ ìˆœì°¨ì ìœ¼ë¡œ ë¡œë”©
        console.log('Face Landmark ëª¨ë¸ ë¡œë”© ì¤‘...');
        await faceapi.nets.faceLandmark68Net.loadFromUri('/models');

        console.log('Face Expression ëª¨ë¸ ë¡œë”© ì¤‘...');
        await faceapi.nets.faceExpressionNet.loadFromUri('/models');

        console.log('Age Gender ëª¨ë¸ ë¡œë”© ì¤‘...');
        await faceapi.nets.ageGenderNet.loadFromUri('/models');

        console.log('ëª¨ë“  ëª¨ë¸ ë¡œë”© ì™„ë£Œ');
        setIsModelLoaded(true);
      } catch (error) {
        console.error('ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨:', error);
        // ê°œë°œ í™˜ê²½ì—ì„œëŠ” ë”ë¯¸ ë°ì´í„° ì‚¬ìš©
        console.log('ë”ë¯¸ ë°ì´í„° ëª¨ë“œë¡œ ì „í™˜');
        setIsModelLoaded(true);
      }
    };

    loadModels();
  }, []);

  const handleFileSelect = useCallback((file: File) => {
    if (file.type.startsWith('image/')) {
      // íŒŒì¼ í¬ê¸° ê²€ì¦ (10MB = 10 * 1024 * 1024 bytes)
      if (file.size > 10 * 1024 * 1024) {
        alert(TEXTS.errorFileSize);
        return;
      }

      setUploadState('image');
      setUploadedFile(file);
      setFileUrl(URL.createObjectURL(file));
    } else {
      alert("ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.");
      return;
    }
  }, [TEXTS.errorFileSize]);

  const handleAnalyze = useCallback(async () => {
    if (!uploadedFile) return;
    if (!isModelLoaded) {
      alert('ëª¨ë¸ì´ ì•„ì§ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
      return;
    }

    setIsAnalyzing(true);
    try {
      // face-api.js ë¶„ì„ ì‹œì‘ (ëª¨ë¸ì´ ì´ë¯¸ ë¡œë“œë¨)
      const faceapi = await import('face-api.js');

      console.log('TinyYolov2 ëª¨ë¸ì„ ì‚¬ìš©í•œ ì–¼êµ´ ê°ì§€ ì‹œì‘...');

      // ì´ë¯¸ì§€ URLì„ fetchí•˜ì—¬ blobìœ¼ë¡œ ë³€í™˜
      const response = await fetch(fileUrl);
      const blob = await response.blob();
      const img = await faceapi.bufferToImage(blob);

      // ì–¼êµ´ ê°ì§€ ë° ë¶„ì„
      const detections = await faceapi
        .detectAllFaces(img, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceExpressions()
        .withAgeAndGender();

      console.log(`ì–¼êµ´ ê°ì§€ ì™„ë£Œ: ${detections.length}ê°œ ì–¼êµ´ ë°œê²¬`);

      if (detections.length === 0) {
        throw new Error('ì–¼êµ´ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
      }

      const detection = detections[0];
      const emotions = detection.expressions;
      const age = Math.round(detection.age);
      const gender = detection.gender;

      console.log('ê°ì • ë¶„ì„ ê²°ê³¼:', emotions);
      console.log('ì¶”ê°€ ì •ë³´:', { age, gender });

      // ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ í‘œì‹œ
      const dominantEmotion = Object.entries(emotions).reduce((a, b) =>
        emotions[a[0] as keyof typeof emotions] > emotions[b[0] as keyof typeof emotions] ? a : b
      )[0] as keyof typeof emotions;

      const emotionLabels = {
        happy: "í–‰ë³µ",
        sad: "ìŠ¬í””",
        angry: "í™”ë‚¨",
        fearful: "ë‘ë ¤ì›€",
        surprised: "ë†€ëŒ",
        disgusted: "í˜ì˜¤",
        neutral: "ì¤‘ë¦½"
      };

      const dominantScore = emotions[dominantEmotion] as number;
      const dominantLabel = emotionLabels[dominantEmotion as keyof typeof emotionLabels] || dominantEmotion;

      // AI ë¬¸êµ¬ ìƒì„± (ë”ë¯¸ ë°ì´í„°)
      const aiPhrases = [
        "ì˜¤ëŠ˜ì€ ì •ë§ ì¢‹ì€ í•˜ë£¨ë„¤ìš”! âœ¨",
        "ì•½ê°„ í”¼ê³¤í•´ ë³´ì´ì‹œëŠ”ë°, í‘¹ ì‰¬ì„¸ìš”! ğŸ˜´",
        "ë°ì€ ë¯¸ì†Œê°€ ì •ë§ ì˜ˆì˜ë„¤ìš”! ğŸ˜Š",
        "ì˜¤ëŠ˜ í•˜ë£¨ë„ í™”ì´íŒ…! ğŸ’ª",
        "í‰ì˜¨í•œ í‘œì •ì´ ì¢‹ì•„ìš”! ğŸ§˜â€â™€ï¸",
        "ì—ë„ˆì§€ê°€ ë„˜ì¹˜ëŠ” í•˜ë£¨ë„¤ìš”! âš¡",
        "ì°¨ë¶„í•˜ê³  ì•ˆì •ì ì¸ ê¸°ë¶„ì´ ëŠê»´ì ¸ìš”! ğŸŒ¸",
        "ì˜¤ëŠ˜ë„ ìˆ˜ê³ í•˜ì…¨ì–´ìš”! ğŸ‘"
      ];

      const aiPhrase = aiPhrases[Math.floor(Math.random() * aiPhrases.length)];

      // ë¶„ì„ ê²°ê³¼ ì €ì¥
      const result = {
        emotions,
        age,
        gender,
        dominantEmotion,
        dominantLabel,
        dominantScore,
        emotionLabels,
        aiPhrase
      };

      setAnalysisResult(result);

    } catch (error) {
      console.error('ë¶„ì„ ì˜¤ë¥˜:', error);
      alert(`ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`);
    } finally {
      setIsAnalyzing(false);
    }
  }, [uploadedFile, fileUrl, isModelLoaded]);

  const handleReset = useCallback(() => {
    setUploadState('before');
    setUploadedFile(null);
    if (fileUrl) {
      URL.revokeObjectURL(fileUrl);
      setFileUrl('');
    }
  }, [fileUrl]);

  return (
    <>
      {/* ì—…ë¡œë“œ ì „ ìƒíƒœ */}
      {uploadState === 'before' && <>
        <UploadBefore onFileSelect={handleFileSelect} />
        <SupportedFormats />
      </>
      }

      {/* ì—…ë¡œë“œ í›„ - ì‚¬ì§„ */}
      {uploadState === 'image' && uploadedFile && (
        <ImageUpload
          fileUrl={fileUrl}
          onReset={handleReset}
          onAnalyze={handleAnalyze}
          isAnalyzing={isAnalyzing}
          isModelLoaded={isModelLoaded}
          analysisResult={analysisResult}
        />
      )}
    </>
  );
}
