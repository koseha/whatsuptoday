import { useEffect, useState } from 'react';

export interface FaceAnalysisResult {
  dominantEmotion: string;
  dominantLabel: string;
  dominantScore: number;
  age: number;
  gender: string;
  emotions: Record<string, number>;
}

export type AnalysisState = 'analyzing' | 'analyzed' | 'analyzing';

export const useFaceAnalysis = (fileUrl: string, modelsLoaded: boolean) => {
  const [analysisState, setAnalysisState] = useState<AnalysisState>('analyzing');
  const [analysisResult, setAnalysisResult] = useState<FaceAnalysisResult | null>(null);
  const [showTextAnimation, setShowTextAnimation] = useState<boolean>(false);

  // ëª¨ë¸ì´ ë¡œë“œë˜ë©´ ìë™ìœ¼ë¡œ ë¶„ì„ ì‹œì‘
  useEffect(() => {
    if (!modelsLoaded) return;

    const analyzeImage = async () => {
      const analysisStartTime = performance.now();
      console.log('ğŸ” ì–¼êµ´ ë¶„ì„ ì‹œì‘...');

      const minimumWaitTime = 3000;

      try {
        // ë¶„ì„ ì‘ì—…ê³¼ ìµœì†Œ ëŒ€ê¸° ì‹œê°„ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
        const [analysisResult] = await Promise.all([
          performAnalysis(), // ì‹¤ì œ ë¶„ì„ í•¨ìˆ˜
          new Promise(resolve => setTimeout(resolve, minimumWaitTime)) // ìµœì†Œ ëŒ€ê¸°
        ]);

        setAnalysisResult(analysisResult);

        // í…ìŠ¤íŠ¸ ì• ë‹ˆë©”ì´ì…˜ íŠ¸ë¦¬ê±°
        setShowTextAnimation(true);

        // ì• ë‹ˆë©”ì´ì…˜ í›„ ìƒíƒœ ë³€ê²½
        setTimeout(() => {
          setAnalysisState('analyzed');
        }, 400); // ì• ë‹ˆë©”ì´ì…˜ ì‹œê°„ê³¼ ë™ì¼

        const totalTime = performance.now() - analysisStartTime;
        console.log(`âœ… ì „ì²´ ì†Œìš” ì‹œê°„: ${totalTime.toFixed(2)}ms`);

      } catch (error) {
        // ì—ëŸ¬ ì‹œì—ë„ ìµœì†Œ ì‹œê°„ì€ ë³´ì¥ë¨ (Promise.all íŠ¹ì„±)
        console.error(`âŒ ë¶„ì„ ì‹¤íŒ¨:`, error);
        alert(`ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`);
        setAnalysisState('analyzing');
      }
    };

    // ì‹¤ì œ ë¶„ì„ ë¡œì§ì„ ë³„ë„ í•¨ìˆ˜ë¡œ ë¶„ë¦¬
    const performAnalysis = async (): Promise<FaceAnalysisResult> => {
      const faceapi = await import('face-api.js');

      console.log('TinyYolov2 ëª¨ë¸ì„ ì‚¬ìš©í•œ ì–¼êµ´ ê°ì§€ ì‹œì‘...');

      // ì´ë¯¸ì§€ ë¡œë“œ
      const imageLoadStartTime = performance.now();
      const response = await fetch(fileUrl);
      const blob = await response.blob();
      const img = await faceapi.bufferToImage(blob);
      const imageLoadTime = performance.now() - imageLoadStartTime;
      console.log(`ğŸ“· ì´ë¯¸ì§€ ë¡œë“œ ì‹œê°„: ${imageLoadTime.toFixed(2)}ms`);

      // ì–¼êµ´ ê°ì§€ ë° ë¶„ì„
      const detectionStartTime = performance.now();
      const detections = await faceapi
        .detectAllFaces(img, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceExpressions()
        .withAgeAndGender();
      const detectionTime = performance.now() - detectionStartTime;
      console.log(`ğŸ¯ ì–¼êµ´ ê°ì§€ ì‹œê°„: ${detectionTime.toFixed(2)}ms`);

      console.log(`ì–¼êµ´ ê°ì§€ ì™„ë£Œ: ${detections.length}ê°œ ì–¼êµ´ ë°œê²¬`);

      if (detections.length === 0) {
        throw new Error('ì–¼êµ´ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
      }

      const detection = detections[0];
      const emotions = detection.expressions;
      const age = Math.round(detection.age);
      const gender = detection.gender;

      console.log('ê°ì • ë¶„ì„ ê²°ê³¼:', emotions);
      console.log('ì¶”ê°€ ì •ë³´:', { age, gender });

      // ê²°ê³¼ ì²˜ë¦¬
      const dominantEmotion = Object.entries(emotions).reduce((a, b) =>
        emotions[a[0] as keyof typeof emotions] > emotions[b[0] as keyof typeof emotions] ? a : b
      )[0] as keyof typeof emotions;

      const emotionLabels = {
        happy: "í–‰ë³µ",
        sad: "ìŠ¬í””",
        angry: "í™”ë‚¨",
        fearful: "ë‘ë ¤ì›€",
        surprised: "ë†€ëŒ",
        disgusted: "í˜ì˜¤",
        neutral: "ì¤‘ë¦½"
      };

      const dominantScore = emotions[dominantEmotion] as number;
      const dominantLabel = emotionLabels[dominantEmotion as keyof typeof emotionLabels] || dominantEmotion;

      return {
        dominantEmotion: dominantEmotion as string,
        dominantLabel,
        dominantScore,
        age,
        gender: gender as string,
        emotions: emotions as unknown as Record<string, number>
      };
    };

    analyzeImage();
  }, [fileUrl, modelsLoaded]);

  return {
    analysisState,
    analysisResult,
    showTextAnimation
  };
};
